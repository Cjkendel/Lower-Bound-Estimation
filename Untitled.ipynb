{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataloader import DataLoader\n",
    "from utils import tensordot_pytorch\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "class EstimateLowerBound:\n",
    "    def __init__(self, batch_size=False, full_batch=False, n_batch=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.full_batch = full_batch\n",
    "        self.n_batch = n_batch\n",
    "        self.trainloader = DataLoader('candy-data.csv', batch_size=self.batch_size,\n",
    "                                      full_batch=self.full_batch, n_batch=self.n_batch,\n",
    "                                      standardize=True)\n",
    "        self.input_dims = self.trainloader.input_dims\n",
    "        self.output_dims = self.trainloader.output_dims\n",
    "        self.prior_var = torch.eye(self.input_dims)\n",
    "        self.prior_precision = torch.inverse(self.prior_var)\n",
    "        self.prior_mean = torch.zeros(self.input_dims)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_epsilon(x, variance, mean):\n",
    "        XT = x.unsqueeze(1)\n",
    "        X = x.unsqueeze(2)\n",
    "        mean = mean.reshape(mean.shape[0], 1)\n",
    "        eps = torch.sqrt(XT @ variance @ X + (XT @ mean) ** 2)\n",
    "        eps = eps.reshape(-1)\n",
    "        return eps\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_lambda(epsilon):\n",
    "        lambda_vals = torch.tanh(epsilon / 2) / (4 * epsilon)\n",
    "        lambda_vals = lambda_vals.reshape(-1)\n",
    "        return lambda_vals\n",
    "\n",
    "    def calculate_precision(self, x, lambda_vals):\n",
    "        XT = x.unsqueeze(1)\n",
    "        X = x.unsqueeze(2)\n",
    "        vec = torch.matmul(X, XT)\n",
    "        precision = 2 * tensordot_pytorch(lambda_vals.t(), vec, axes=1) + self.prior_precision\n",
    "        return precision\n",
    "\n",
    "    def calculate_mean(self, variance, x, y):\n",
    "        halves = torch.ones((y.size()[0])) * 0.5\n",
    "        product = (y - halves).unsqueeze(1)\n",
    "        sum = (product * x).sum(0)\n",
    "        mean = (self.prior_precision @ self.prior_mean) + sum\n",
    "        mean = variance @ mean.t()\n",
    "        mean = mean.reshape(-1)\n",
    "        return mean\n",
    "\n",
    "    def calculate_loss(self, variance, precision, mean, lambdas, epsilons):\n",
    "        L = (-torch.log(1 + torch.exp(-epsilons)).sum() - (epsilons / 2).sum() + (lambdas * epsilons ** 2).sum()\n",
    "             - 0.5 * (self.prior_mean.t() @ self.prior_precision @ self.prior_mean)\n",
    "             + 0.5 * (mean.t() @ precision @ mean)\n",
    "             + 0.5 * torch.log(torch.div(\n",
    "                    torch.det(variance), torch.det(self.prior_var)\n",
    "                )\n",
    "                )\n",
    "             )\n",
    "        return L\n",
    "\n",
    "    def do_call(self, variance, mean, x, y):\n",
    "        epsilons = self.__class__.calculate_epsilon(x, variance, mean)\n",
    "        lambda_vals = self.__class__.calculate_lambda(epsilons)\n",
    "        precision = self.calculate_precision(x, lambda_vals)\n",
    "        variance = torch.inverse(precision)\n",
    "        mean = self.calculate_mean(variance, x, y)\n",
    "\n",
    "        return epsilons, lambda_vals, precision, variance, mean\n",
    "\n",
    "    def __call__(self, x, y, threshold=0.0001, max_iters=100):\n",
    "        variance = self.prior_var\n",
    "        mean = self.prior_mean\n",
    "        lossprev = 0\n",
    "        i = 0\n",
    "        while threshold is not False:\n",
    "            epsilons, lambda_vals, precision, variance, mean = self.do_call(variance, mean, x, y)\n",
    "            loss = self.calculate_loss(variance, precision, mean, lambda_vals, epsilons)\n",
    "            self.prior_mean = mean\n",
    "            self.prior_var = variance\n",
    "            self.prior_precision = precision\n",
    "            if abs(loss / lossprev - 1) < threshold or abs(lossprev / loss - 1) < threshold:\n",
    "                threshold = False\n",
    "            lossprev = loss\n",
    "            i += 1\n",
    "            if i > max_iters:\n",
    "                break\n",
    "\n",
    "        return mean, variance\n",
    "\n",
    "    def estimate_lower_bound(self, epochs=1):\n",
    "        with torch.no_grad():\n",
    "            batch_mean_variance = torch.zeros((self.trainloader.num_batches, self.input_dims, self.input_dims))\n",
    "            batch_mean_mean = torch.zeros((self.trainloader.num_batches, self.input_dims))\n",
    "            for epoch in range(epochs):\n",
    "                for i, (x, y) in enumerate(self.trainloader):\n",
    "                    means, variance = self.__call__(x, y)\n",
    "                    batch_mean_mean[i::] = means\n",
    "                    batch_mean_variance[i::] = variance\n",
    "                self.prior_mean = torch.mean(batch_mean_mean, dim=0)\n",
    "                self.prior_var = torch.mean(batch_mean_variance, dim=0)\n",
    "                self.prior_precision = torch.inverse(torch.mean(batch_mean_variance, dim=0))\n",
    "                print(f'Epoch: {epoch} \\n JJ Means: {means} \\n JJ Variances: {torch.diag(variance)}')\n",
    "\n",
    "        return means, variance, batch_mean_mean, batch_mean_variance\n",
    "\n",
    "    def call_and_write_results(self, epochs=1):\n",
    "        means, variance, _, _ = self.estimate_lower_bound(epochs)\n",
    "        results = f' \\n \\n DataSet: {self.trainloader.filename} \\n' \\\n",
    "                  f'Lower bound trial with BatchSize: {self.trainloader.batch_size} | Epochs: {epochs} \\n' \\\n",
    "                  f'JJ Means: {means} \\n JJ Variances: {torch.diag(variance)} \\n \\n'\n",
    "        file = open(\"Lower_Bound_Results.txt\", \"a\")\n",
    "        file.write(results)\n",
    "        file.close()\n",
    "\n",
    "    def gen_plot_data(self, batch_sizes=None):\n",
    "        coef_list = []\n",
    "        for i, batch in enumerate(batch_sizes):\n",
    "            self.trainloader = DataLoader('candy-data.csv', batch_size=batch,\n",
    "                                          full_batch=self.full_batch, n_batch=self.n_batch,\n",
    "                                          standardize=True)\n",
    "            _, _, bmeans, bvars = self.estimate_lower_bound()\n",
    "            coef_list.append(bmeans)\n",
    "        return coef_list\n",
    "\n",
    "    def baseline_plots(self, batch_sizes=None):\n",
    "        data = self.gen_plot_data(batch_sizes)\n",
    "        data_dict = {}\n",
    "        for j in range(data[0].size()[1]):\n",
    "            data_dict[\"mean_\" + str(j)] = []\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            for j in range(data[i].size()[1]):\n",
    "                data_dict[\"mean_\" + str(j)].append(data[i][:, j])\n",
    "\n",
    "        legend = [f\" size = {size}\" for size in batch_sizes]\n",
    "        \n",
    "        return data_dict, legend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = EstimateLowerBound(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      " JJ Means: tensor([-3.8263, -0.7114, -1.6951, -1.7031,  0.9903,  0.5924,  2.1155, -0.4740,\n",
      "         0.2191,  1.2156,  8.0337, -2.7094]) \n",
      " JJ Variances: tensor([0.0017, 0.0027, 0.0034, 0.0073, 0.0086, 0.0023, 0.0060, 0.0018, 0.0040,\n",
      "        0.0055, 0.0082, 0.0033])\n",
      "Epoch: 0 \n",
      " JJ Means: tensor([-3.8436, -0.7279, -1.7054, -1.7125,  0.9868,  0.5901,  2.1268, -0.4628,\n",
      "         0.2158,  1.2107,  8.0205, -2.6939]) \n",
      " JJ Variances: tensor([0.0017, 0.0026, 0.0033, 0.0073, 0.0087, 0.0023, 0.0059, 0.0018, 0.0040,\n",
      "        0.0055, 0.0082, 0.0033])\n",
      "Epoch: 0 \n",
      " JJ Means: tensor([-3.8706, -0.7197, -1.7087, -1.7018,  0.9828,  0.6362,  2.1029, -0.4801,\n",
      "         0.2096,  1.2541,  8.0905, -2.7281]) \n",
      " JJ Variances: tensor([0.0015, 0.0024, 0.0030, 0.0065, 0.0076, 0.0021, 0.0052, 0.0016, 0.0036,\n",
      "        0.0050, 0.0074, 0.0030])\n",
      "Epoch: 0 \n",
      " JJ Means: tensor([-3.8822, -0.7429, -1.7108, -1.6876,  0.9946,  0.6266,  2.1264, -0.4492,\n",
      "         0.1941,  1.2213,  8.0795, -2.7111]) \n",
      " JJ Variances: tensor([0.0015, 0.0023, 0.0030, 0.0065, 0.0076, 0.0021, 0.0052, 0.0016, 0.0036,\n",
      "        0.0049, 0.0073, 0.0029])\n",
      "Epoch: 0 \n",
      " JJ Means: tensor([-3.8941, -0.7543, -1.7064, -1.6741,  0.9988,  0.6392,  2.1453, -0.4315,\n",
      "         0.1832,  1.2205,  8.1010, -2.7281]) \n",
      " JJ Variances: tensor([0.0014, 0.0022, 0.0028, 0.0061, 0.0071, 0.0020, 0.0049, 0.0015, 0.0034,\n",
      "        0.0046, 0.0069, 0.0028])\n"
     ]
    }
   ],
   "source": [
    "data, legend = reg.baseline_plots([1,16,32,50,reg.trainloader.total_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(legend[-1].split()[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7fb246bff1d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data[\"mean_0\"][0])\n",
    "plt.plot(data[\"mean_0\"][1])\n",
    "plt.plot(data[\"mean_0\"][2])\n",
    "plt.plot(data[\"mean_0\"][3])\n",
    "plt.hlines(-3.68,0,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_0': [tensor([-3.8201, -3.8210, -3.8215, -3.8219, -3.8219, -3.8217, -3.8223, -3.8233,\n",
       "          -3.8238, -3.8215, -3.8268, -3.8272, -3.8306, -3.8312, -3.8312, -3.8320,\n",
       "          -3.8325, -3.8326, -3.8329, -3.8330, -3.8331, -3.8334, -3.8335, -3.8367,\n",
       "          -3.8368, -3.8369, -3.8370, -3.8371, -3.8371, -3.8381, -3.8401, -3.8360,\n",
       "          -3.8360, -3.8363, -3.8366, -3.8370, -3.8370, -3.8372, -3.8377, -3.8322,\n",
       "          -3.8323, -3.8321, -3.8267, -3.8229, -3.8230, -3.8231, -3.8235, -3.8244,\n",
       "          -3.8246, -3.8263, -3.8269, -3.8269, -3.8269, -3.8268, -3.8268, -3.8268,\n",
       "          -3.8263, -3.8264, -3.8265, -3.8265, -3.8278, -3.8279, -3.8279, -3.8280,\n",
       "          -3.8289, -3.8292, -3.8294, -3.8295, -3.8292, -3.8244, -3.8223, -3.8224,\n",
       "          -3.8225, -3.8266, -3.8273, -3.8277, -3.8272, -3.8272, -3.8246, -3.8246,\n",
       "          -3.8246, -3.8251, -3.8251, -3.8263, -3.8263, -3.8263]),\n",
       "  tensor([-3.8294, -3.8386, -3.8428, -3.8461, -3.8428, -3.8436]),\n",
       "  tensor([-3.8551, -3.8839, -3.8706]),\n",
       "  tensor([-3.8633, -3.8822]),\n",
       "  tensor([-3.8941, -3.8941])],\n",
       " 'mean_1': [tensor([-0.7262, -0.7192, -0.7192, -0.7193, -0.7193, -0.7194, -0.7193, -0.7202,\n",
       "          -0.7213, -0.7271, -0.7319, -0.7322, -0.7331, -0.7335, -0.7335, -0.7333,\n",
       "          -0.7334, -0.7331, -0.7332, -0.7329, -0.7330, -0.7331, -0.7329, -0.7324,\n",
       "          -0.7326, -0.7327, -0.7328, -0.7327, -0.7327, -0.7335, -0.7331, -0.7292,\n",
       "          -0.7292, -0.7289, -0.7283, -0.7284, -0.7283, -0.7285, -0.7289, -0.7150,\n",
       "          -0.7150, -0.7150, -0.7124, -0.7110, -0.7110, -0.7110, -0.7071, -0.7082,\n",
       "          -0.7083, -0.7089, -0.7098, -0.7098, -0.7098, -0.7105, -0.7103, -0.7103,\n",
       "          -0.7125, -0.7126, -0.7126, -0.7126, -0.7127, -0.7127, -0.7127, -0.7128,\n",
       "          -0.7147, -0.7147, -0.7148, -0.7148, -0.7139, -0.7115, -0.7102, -0.7103,\n",
       "          -0.7104, -0.7114, -0.7116, -0.7114, -0.7127, -0.7126, -0.7121, -0.7119,\n",
       "          -0.7115, -0.7115, -0.7113, -0.7113, -0.7114, -0.7114]),\n",
       "  tensor([-0.7109, -0.7177, -0.7204, -0.7309, -0.7299, -0.7279]),\n",
       "  tensor([-0.7426, -0.7332, -0.7197]),\n",
       "  tensor([-0.7381, -0.7429]),\n",
       "  tensor([-0.7543, -0.7543])],\n",
       " 'mean_2': [tensor([-1.7100, -1.7117, -1.7119, -1.7119, -1.7119, -1.7109, -1.7108, -1.7123,\n",
       "          -1.7139, -1.7133, -1.7184, -1.7188, -1.7197, -1.7205, -1.7203, -1.7208,\n",
       "          -1.7205, -1.7208, -1.7208, -1.7210, -1.7212, -1.7214, -1.7214, -1.7190,\n",
       "          -1.7195, -1.7199, -1.7201, -1.7200, -1.7198, -1.7165, -1.7154, -1.7103,\n",
       "          -1.7103, -1.7100, -1.7096, -1.7096, -1.7096, -1.7093, -1.7071, -1.6916,\n",
       "          -1.6916, -1.6902, -1.6884, -1.6889, -1.6889, -1.6890, -1.6951, -1.6931,\n",
       "          -1.6932, -1.6942, -1.6944, -1.6955, -1.6955, -1.6955, -1.6957, -1.6958,\n",
       "          -1.6956, -1.6958, -1.6960, -1.6960, -1.6956, -1.6957, -1.6957, -1.6957,\n",
       "          -1.6976, -1.6976, -1.6967, -1.6967, -1.6959, -1.6948, -1.6944, -1.6944,\n",
       "          -1.6944, -1.6943, -1.6942, -1.6944, -1.6950, -1.6950, -1.6950, -1.6948,\n",
       "          -1.6956, -1.6957, -1.6957, -1.6951, -1.6951, -1.6951]),\n",
       "  tensor([-1.7037, -1.7106, -1.7105, -1.7132, -1.7116, -1.7054]),\n",
       "  tensor([-1.7155, -1.7173, -1.7087]),\n",
       "  tensor([-1.6916, -1.7108]),\n",
       "  tensor([-1.7064, -1.7064])],\n",
       " 'mean_3': [tensor([-1.7190, -1.7207, -1.7206, -1.7206, -1.7206, -1.7227, -1.7223, -1.7213,\n",
       "          -1.7184, -1.7169, -1.7146, -1.7145, -1.7146, -1.7142, -1.7146, -1.7150,\n",
       "          -1.7151, -1.7149, -1.7149, -1.7150, -1.7159, -1.7160, -1.7159, -1.7171,\n",
       "          -1.7183, -1.7190, -1.7189, -1.7190, -1.7190, -1.7198, -1.7184, -1.7216,\n",
       "          -1.7217, -1.7217, -1.7216, -1.7218, -1.7218, -1.7219, -1.7222, -1.7009,\n",
       "          -1.7009, -1.7032, -1.7039, -1.7033, -1.7033, -1.7033, -1.7160, -1.7165,\n",
       "          -1.7164, -1.7161, -1.7135, -1.7133, -1.7133, -1.7130, -1.7127, -1.7127,\n",
       "          -1.7117, -1.7117, -1.7116, -1.7116, -1.7117, -1.7117, -1.7118, -1.7117,\n",
       "          -1.7065, -1.7063, -1.7064, -1.7063, -1.7047, -1.7037, -1.7041, -1.7041,\n",
       "          -1.7041, -1.7044, -1.7045, -1.7047, -1.7043, -1.7043, -1.7042, -1.7043,\n",
       "          -1.7030, -1.7030, -1.7030, -1.7031, -1.7031, -1.7031]),\n",
       "  tensor([-1.7283, -1.7149, -1.7129, -1.7105, -1.7052, -1.7125]),\n",
       "  tensor([-1.7049, -1.6926, -1.7018]),\n",
       "  tensor([-1.6793, -1.6876]),\n",
       "  tensor([-1.6741, -1.6741])],\n",
       " 'mean_4': [tensor([0.9946, 0.9916, 0.9915, 0.9914, 0.9914, 0.9899, 0.9901, 0.9895, 0.9889,\n",
       "          0.9904, 0.9892, 0.9889, 0.9891, 0.9887, 0.9883, 0.9877, 0.9880, 0.9877,\n",
       "          0.9877, 0.9874, 0.9866, 0.9865, 0.9865, 0.9885, 0.9871, 0.9862, 0.9861,\n",
       "          0.9862, 0.9862, 0.9861, 0.9875, 0.9889, 0.9888, 0.9889, 0.9895, 0.9894,\n",
       "          0.9894, 0.9894, 0.9894, 0.9895, 0.9895, 0.9880, 0.9878, 0.9870, 0.9870,\n",
       "          0.9869, 0.9842, 0.9841, 0.9841, 0.9836, 0.9902, 0.9897, 0.9897, 0.9898,\n",
       "          0.9897, 0.9897, 0.9904, 0.9907, 0.9905, 0.9905, 0.9909, 0.9908, 0.9908,\n",
       "          0.9908, 0.9909, 0.9908, 0.9908, 0.9908, 0.9906, 0.9906, 0.9898, 0.9898,\n",
       "          0.9898, 0.9910, 0.9912, 0.9908, 0.9906, 0.9906, 0.9899, 0.9903, 0.9898,\n",
       "          0.9897, 0.9896, 0.9901, 0.9903, 0.9903]),\n",
       "  tensor([0.9897, 0.9877, 0.9881, 0.9865, 0.9875, 0.9868]),\n",
       "  tensor([0.9924, 0.9991, 0.9828]),\n",
       "  tensor([1.0042, 0.9946]),\n",
       "  tensor([0.9988, 0.9988])],\n",
       " 'mean_5': [tensor([0.5964, 0.5963, 0.5969, 0.5971, 0.5971, 0.5972, 0.5981, 0.5982, 0.5983,\n",
       "          0.5934, 0.5898, 0.5898, 0.5895, 0.5896, 0.5896, 0.5874, 0.5874, 0.5868,\n",
       "          0.5870, 0.5870, 0.5869, 0.5855, 0.5848, 0.5864, 0.5864, 0.5865, 0.5861,\n",
       "          0.5855, 0.5855, 0.5857, 0.5885, 0.5906, 0.5906, 0.5913, 0.5871, 0.5872,\n",
       "          0.5871, 0.5871, 0.5873, 0.5865, 0.5866, 0.5865, 0.5881, 0.5836, 0.5837,\n",
       "          0.5838, 0.5837, 0.5830, 0.5833, 0.5834, 0.5833, 0.5834, 0.5834, 0.5838,\n",
       "          0.5837, 0.5836, 0.5842, 0.5843, 0.5845, 0.5845, 0.5853, 0.5854, 0.5854,\n",
       "          0.5854, 0.5851, 0.5856, 0.5858, 0.5859, 0.5860, 0.5882, 0.5901, 0.5902,\n",
       "          0.5902, 0.5890, 0.5892, 0.5880, 0.5910, 0.5910, 0.5915, 0.5915, 0.5916,\n",
       "          0.5922, 0.5919, 0.5924, 0.5924, 0.5924]),\n",
       "  tensor([0.5903, 0.5905, 0.5888, 0.5844, 0.5877, 0.5901]),\n",
       "  tensor([0.5789, 0.6314, 0.6362]),\n",
       "  tensor([0.6348, 0.6266]),\n",
       "  tensor([0.6392, 0.6392])],\n",
       " 'mean_6': [tensor([2.1157, 2.1151, 2.1154, 2.1152, 2.1152, 2.1171, 2.1167, 2.1149, 2.1149,\n",
       "          2.1166, 2.1055, 2.1052, 2.1063, 2.1058, 2.1062, 2.1063, 2.1062, 2.1062,\n",
       "          2.1059, 2.1057, 2.1068, 2.1060, 2.1057, 2.1077, 2.1091, 2.1098, 2.1094,\n",
       "          2.1094, 2.1092, 2.1075, 2.1063, 2.1163, 2.1164, 2.1173, 2.1157, 2.1158,\n",
       "          2.1160, 2.1153, 2.1143, 2.1168, 2.1168, 2.1190, 2.1211, 2.1191, 2.1191,\n",
       "          2.1190, 2.1192, 2.1161, 2.1160, 2.1161, 2.1129, 2.1130, 2.1130, 2.1133,\n",
       "          2.1134, 2.1133, 2.1137, 2.1137, 2.1135, 2.1135, 2.1134, 2.1134, 2.1135,\n",
       "          2.1133, 2.1137, 2.1135, 2.1130, 2.1130, 2.1131, 2.1139, 2.1166, 2.1167,\n",
       "          2.1166, 2.1181, 2.1176, 2.1178, 2.1161, 2.1161, 2.1150, 2.1151, 2.1151,\n",
       "          2.1154, 2.1156, 2.1156, 2.1155, 2.1155]),\n",
       "  tensor([2.1250, 2.1192, 2.1203, 2.1202, 2.1164, 2.1268]),\n",
       "  tensor([2.1426, 2.0818, 2.1029]),\n",
       "  tensor([2.1353, 2.1264]),\n",
       "  tensor([2.1453, 2.1453])],\n",
       " 'mean_7': [tensor([-0.4715, -0.4690, -0.4684, -0.4686, -0.4686, -0.4686, -0.4687, -0.4681,\n",
       "          -0.4683, -0.4674, -0.4753, -0.4753, -0.4730, -0.4727, -0.4727, -0.4718,\n",
       "          -0.4722, -0.4716, -0.4719, -0.4718, -0.4718, -0.4727, -0.4731, -0.4742,\n",
       "          -0.4742, -0.4742, -0.4745, -0.4748, -0.4749, -0.4744, -0.4749, -0.4687,\n",
       "          -0.4688, -0.4678, -0.4697, -0.4699, -0.4698, -0.4702, -0.4697, -0.4676,\n",
       "          -0.4676, -0.4675, -0.4700, -0.4723, -0.4723, -0.4724, -0.4724, -0.4745,\n",
       "          -0.4746, -0.4735, -0.4735, -0.4737, -0.4737, -0.4734, -0.4734, -0.4735,\n",
       "          -0.4739, -0.4739, -0.4740, -0.4740, -0.4747, -0.4746, -0.4746, -0.4747,\n",
       "          -0.4751, -0.4752, -0.4749, -0.4750, -0.4748, -0.4755, -0.4728, -0.4727,\n",
       "          -0.4728, -0.4699, -0.4705, -0.4699, -0.4722, -0.4722, -0.4743, -0.4742,\n",
       "          -0.4742, -0.4736, -0.4733, -0.4739, -0.4740, -0.4740]),\n",
       "  tensor([-0.4644, -0.4709, -0.4679, -0.4643, -0.4677, -0.4628]),\n",
       "  tensor([-0.4434, -0.4719, -0.4801]),\n",
       "  tensor([-0.4387, -0.4492]),\n",
       "  tensor([-0.4315, -0.4315])],\n",
       " 'mean_8': [tensor([0.2330, 0.2296, 0.2297, 0.2300, 0.2300, 0.2295, 0.2272, 0.2251, 0.2253,\n",
       "          0.2283, 0.2286, 0.2290, 0.2276, 0.2268, 0.2268, 0.2292, 0.2301, 0.2289,\n",
       "          0.2295, 0.2297, 0.2299, 0.2307, 0.2302, 0.2313, 0.2310, 0.2308, 0.2307,\n",
       "          0.2309, 0.2308, 0.2329, 0.2246, 0.2312, 0.2312, 0.2301, 0.2278, 0.2284,\n",
       "          0.2284, 0.2286, 0.2288, 0.2271, 0.2271, 0.2272, 0.2253, 0.2213, 0.2212,\n",
       "          0.2211, 0.2223, 0.2253, 0.2250, 0.2235, 0.2245, 0.2245, 0.2245, 0.2243,\n",
       "          0.2244, 0.2243, 0.2225, 0.2224, 0.2224, 0.2225, 0.2231, 0.2231, 0.2232,\n",
       "          0.2233, 0.2243, 0.2233, 0.2230, 0.2230, 0.2226, 0.2126, 0.2138, 0.2137,\n",
       "          0.2138, 0.2132, 0.2145, 0.2157, 0.2170, 0.2170, 0.2189, 0.2189, 0.2188,\n",
       "          0.2189, 0.2185, 0.2191, 0.2191, 0.2191]),\n",
       "  tensor([0.2234, 0.2244, 0.2195, 0.2187, 0.2199, 0.2158]),\n",
       "  tensor([0.2060, 0.1979, 0.2096]),\n",
       "  tensor([0.1969, 0.1941]),\n",
       "  tensor([0.1832, 0.1832])],\n",
       " 'mean_9': [tensor([1.2068, 1.2087, 1.2092, 1.2094, 1.2094, 1.2099, 1.2118, 1.2173, 1.2173,\n",
       "          1.2177, 1.2242, 1.2245, 1.2177, 1.2185, 1.2185, 1.2191, 1.2193, 1.2207,\n",
       "          1.2210, 1.2214, 1.2209, 1.2215, 1.2215, 1.2127, 1.2133, 1.2137, 1.2141,\n",
       "          1.2132, 1.2131, 1.2131, 1.2201, 1.2120, 1.2120, 1.2119, 1.2131, 1.2118,\n",
       "          1.2114, 1.2116, 1.2119, 1.2124, 1.2124, 1.2122, 1.2098, 1.2147, 1.2146,\n",
       "          1.2148, 1.2125, 1.2124, 1.2122, 1.2100, 1.2111, 1.2111, 1.2111, 1.2112,\n",
       "          1.2111, 1.2112, 1.2101, 1.2103, 1.2105, 1.2104, 1.2094, 1.2095, 1.2095,\n",
       "          1.2097, 1.2095, 1.2100, 1.2103, 1.2102, 1.2099, 1.2146, 1.2165, 1.2165,\n",
       "          1.2165, 1.2096, 1.2103, 1.2107, 1.2109, 1.2109, 1.2158, 1.2156, 1.2158,\n",
       "          1.2163, 1.2163, 1.2155, 1.2156, 1.2156]),\n",
       "  tensor([1.1981, 1.1999, 1.1946, 1.2077, 1.2126, 1.2107]),\n",
       "  tensor([1.1813, 1.2303, 1.2541]),\n",
       "  tensor([1.2179, 1.2213]),\n",
       "  tensor([1.2205, 1.2205])],\n",
       " 'mean_10': [tensor([8.0127, 8.0153, 8.0157, 8.0158, 8.0158, 8.0151, 8.0145, 8.0129, 8.0150,\n",
       "          8.0143, 8.0133, 8.0141, 8.0147, 8.0158, 8.0159, 8.0159, 8.0143, 8.0146,\n",
       "          8.0142, 8.0146, 8.0146, 8.0140, 8.0139, 8.0111, 8.0110, 8.0115, 8.0118,\n",
       "          8.0119, 8.0122, 8.0144, 8.0075, 8.0050, 8.0050, 8.0048, 8.0011, 8.0021,\n",
       "          8.0022, 8.0031, 8.0044, 7.9946, 7.9946, 7.9935, 8.0038, 8.0081, 8.0083,\n",
       "          8.0085, 8.0161, 8.0180, 8.0187, 8.0214, 8.0203, 8.0220, 8.0220, 8.0227,\n",
       "          8.0229, 8.0229, 8.0257, 8.0260, 8.0269, 8.0269, 8.0261, 8.0263, 8.0263,\n",
       "          8.0264, 8.0246, 8.0250, 8.0259, 8.0261, 8.0271, 8.0338, 8.0372, 8.0373,\n",
       "          8.0375, 8.0310, 8.0294, 8.0294, 8.0319, 8.0319, 8.0344, 8.0342, 8.0354,\n",
       "          8.0355, 8.0356, 8.0338, 8.0337, 8.0337]),\n",
       "  tensor([8.0177, 8.0194, 8.0229, 8.0195, 8.0255, 8.0205]),\n",
       "  tensor([8.0172, 8.0700, 8.0905]),\n",
       "  tensor([8.0732, 8.0795]),\n",
       "  tensor([8.1010, 8.1010])],\n",
       " 'mean_11': [tensor([-2.6984, -2.6992, -2.7001, -2.7001, -2.7001, -2.7001, -2.6997, -2.6993,\n",
       "          -2.6996, -2.7021, -2.6922, -2.6924, -2.6877, -2.6877, -2.6877, -2.6892,\n",
       "          -2.6888, -2.6893, -2.6893, -2.6896, -2.6894, -2.6889, -2.6883, -2.6841,\n",
       "          -2.6840, -2.6841, -2.6841, -2.6836, -2.6836, -2.6848, -2.6818, -2.6901,\n",
       "          -2.6901, -2.6904, -2.6869, -2.6868, -2.6868, -2.6869, -2.6875, -2.6900,\n",
       "          -2.6900, -2.6897, -2.6964, -2.6986, -2.6986, -2.6987, -2.7010, -2.7006,\n",
       "          -2.7007, -2.6994, -2.6991, -2.6997, -2.6997, -2.7003, -2.7004, -2.7003,\n",
       "          -2.7005, -2.7006, -2.7011, -2.7011, -2.7003, -2.7004, -2.7005, -2.7005,\n",
       "          -2.6991, -2.6990, -2.6994, -2.6993, -2.7000, -2.7044, -2.7115, -2.7116,\n",
       "          -2.7116, -2.7038, -2.7036, -2.7044, -2.7046, -2.7046, -2.7094, -2.7094,\n",
       "          -2.7098, -2.7106, -2.7107, -2.7096, -2.7094, -2.7094]),\n",
       "  tensor([-2.6985, -2.6901, -2.6861, -2.6883, -2.6932, -2.6939]),\n",
       "  tensor([-2.6788, -2.6830, -2.7281]),\n",
       "  tensor([-2.7290, -2.7111]),\n",
       "  tensor([-2.7281, -2.7281])]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = [1,16,32,50,85]\n",
    "legend = [f\" size = {size}\" for size in batch_sizes]\n",
    "legend\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [1,16,32,50,reg.trainloader.total_data_len]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[\"mean_\" + str(i)])):\n",
    "        plt.plot(data[\"mean_\" + str(i)][j])\n",
    "        if j == len(data['mean_0'])-1:\n",
    "            plt.hlines(float(data['mean_' + str(i)][-1][0]), 0, batch_sizes[-1])\n",
    "    plt.legend(legend)\n",
    "    plt.title(f'Mean over batches for Param # {i}')\n",
    "    plt.savefig('Figures/mean_over_batches_param_' + str(i) + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.trainloader.total_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.7543)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['mean_1'][-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
